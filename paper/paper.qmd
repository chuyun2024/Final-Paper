---
title: "2025 US School Shooting Predictions and Solutions"
subtitle: "Leveraging Forecasting to Shape Policy and Protect Communities"
author: 
  - Yun Chu
thanks: "Code and data are available at: https://github.com/chuyun2024/School-Shooting-Analysis."
date: today
date-format: long
abstract: "First sentence. Second sentence. Third sentence. Fourth sentence."
format: pdf
number-sections: true
bibliography: references.bib
---

```{r}
#| include: false
#| warning: false
#| message: false

library(tidyverse)
library(ggplot2)
library(dplyr)
library(maps)

#### Read data ####
data <- read_csv("../data/02-analysis_data/analysis_data.csv")
```


# Introduction

Overview paragraph

Estimand paragraph

Results paragraph

Why it matters paragraph

Telegraphing paragraph: The remainder of this paper is structured as follows. @sec-data....



Paragraph of Estimand!


# Data {#sec-data}

## Overview

The dataset has 416 entries, with each entry representing a unique school shooting incident. Incidents occurring during after-hours events, accidental gun discharges that only injured the individual handling the firearm, and private suicides that did not endanger other children were excluded from consideration. Additionally, shootings at colleges and universities, which involve young adults rather than children, were not included in the analysis [@washingtonpost_school_shootings]. These entries cover 50 variables that provide information about the schools, locations, date and time of shooting, shooters details, number of killed and injured, and the relationship of the shooter to school, the weapon type and source.

As the federal government does not consistently track school shootings, this dataset from *The Washington Post* fills a critical gap. It was carefully assembled using information from diverse sources, including news articles, open-source databases, law enforcement reports, and direct inquiries to schools and police departments. Although sources like FBI crime reports and local school incident logs were reviewed, they lack the detail and comprehensive coverage of this dataset. Its unparalleled breadth and depth make it the strongest foundation for predictive modeling and generating actionable insights.

We use the statistical programming language R [@citeR] to download, clean, analyze and model the US School Shooting Data. The US School Shooting dataset is downloaded from The Washington Post [@washingtonpost_school_shootings_data] . The following libraries are utilized in this paper:

- tidyverse [@tidyverse2024]
- dplyr [@dplyr2024]
- lubridate [@lubridate2024]
- readr [@readr2024]
- stringr [@stringr2024]
- arrow [@arrow2024]
- testthat [@testthat2024]
- randomForest [@randomForest2024]
- ggplot2
- maps


## Measurement

The dataset, compiled by The Washington Post, translates real-world school shooting incidents into structured entries by aggregating information from news articles, open-source databases, law enforcement reports, and direct calls to schools. Only verified incidents, such as shootings during school hours or on school property, were included. Events like after-hours shootings, private suicides, or accidental discharges without other injuries were excluded [@washingtonpost_school_shootings].

## Summary Statistics & Relationship Between Variables

$ Causalities = Killed + Injured $

## Outcome variables

The outcome variable for this analysis is number of causalities for each state in 2025.

@fig-Number_of_Incidents_Over_Time shows the number of school shooting incidents in US since 1999. The number of school shooting incidents almost doubled since 2020 compared with previous years.


```{r}
#| label: fig-Number_of_Incidents_Over_Time
#| fig-cap: "Number of US School Shooting Incidents Over Time"
#| echo: false

ggplot(data, aes(x = date)) +
  geom_histogram(binwidth = 60, fill = '#3FA0FF', color = 'white', alpha = 0.8) +
  labs(
    title = "Number of US School Shooting Incidents Over Time",
    subtitle = "Visualizing school shooting trends in the US",
    x = "Date",
    y = "Incident Count"
  ) +
  theme_minimal(base_size = 14) +
  theme(
    plot.title = element_text(hjust = 0.5, face = "bold", size = 13, margin = margin(b = 15)),
    plot.subtitle = element_text(hjust = 0.5, size = 10, margin = margin(b = 10)),
    axis.title.x = element_text(margin = margin(t = 10)),
    axis.title.y = element_text(margin = margin(r = 10)),
    panel.grid.major = element_line(color = "#E5E5E5"),
    panel.grid.minor = element_blank()
  )

```

@fig-Shooting_Casaulties_by_State visualizes the number of school shooting incidents in US by state for all data since 1999. California, Texas, Florida and North Carolina all have more than 20 school shooting incidents in the past 25 years while other states has less than 20 school shootings.

```{r}
#| label: fig-Shooting_Casaulties_by_State
#| fig-cap: "US School Shooting Casaulties by State"
#| echo: false

# Aggregate data to calculate total casualties by state
state_counts <- data %>%
  group_by(state) %>%
  summarise(total_casualties = sum(casualties, na.rm = TRUE))  

# Get US map data
us_map <- map_data("state")

# Ensure state names are in lowercase to match map_data
state_counts <- state_counts %>%
  mutate(state = tolower(state))

# Merge map data with shooting casualties data
map_data <- us_map %>%
  left_join(state_counts, by = c("region" = "state"))

# Replace NA values in `total_casualties` with 0 (for states with no recorded casualties)
map_data$total_casualties[is.na(map_data$total_casualties)] <- 0

ggplot(map_data, aes(long, lat, group = group, fill = total_casualties)) +
  geom_polygon(color = "white") +
  scale_fill_gradient(
    low = "#E6F7FF",
    high = "#0072B2",
    name = "Total Casualties",
    breaks = c(0, 50, 100, 150, 200)  # Adjust the breaks based on your data
  ) +
  labs(
    title = "US School Shooting Casualties by State",
    subtitle = "Number of casualties visualized geographically",
    x = NULL,
    y = NULL
  ) +
  coord_fixed(1.3) +
  theme_minimal(base_size = 14) +
  theme(
    plot.title = ggplot2::element_text(hjust = 0.5, face = "bold", size = 13, margin = ggplot2::margin(t = 10, b = 10)),
    plot.subtitle = ggplot2::element_text(hjust = 0.5, size = 10, margin = ggplot2::margin(t = 0, b = 20)),
    legend.position = "right",  # Alternative: Use "bottom" for a horizontal legend
    legend.key.height = unit(1, "cm"),  # Adjust legend size
    axis.text = ggplot2::element_blank(),
    axis.ticks = ggplot2::element_blank(),
    panel.grid = ggplot2::element_blank(),
    plot.margin = ggplot2::margin(t = 20, r = 20, b = 20, l = 20)  # Increase margins for PDF export
  )


```

## Predictor variables

Add graphs, tables and text.

Use sub-sub-headings for each outcome variable and feel free to combine a few into one if they go together naturally.








# Model

The goal of our modelling strategy is twofold. Firstly,...

Here we briefly describe the Bayesian analysis model used to investigate... Background details and diagnostics are included in [Appendix -@sec-model-details].

## Model set-up

Define $y_i$ as the number of seconds that the plane remained aloft. Then $\beta_i$ is the wing width and $\gamma_i$ is the wing length, both measured in millimeters.  

\begin{align} 
y_i|\mu_i, \sigma &\sim \mbox{Normal}(\mu_i, \sigma) \\
\mu_i &= \alpha + \beta_i + \gamma_i\\
\alpha &\sim \mbox{Normal}(0, 2.5) \\
\beta &\sim \mbox{Normal}(0, 2.5) \\
\gamma &\sim \mbox{Normal}(0, 2.5) \\
\sigma &\sim \mbox{Exponential}(1)
\end{align}

We run the model in R [@citeR] using the `rstanarm` package of @rstanarm. We use the default priors from `rstanarm`.


### Model justification

We expect a positive relationship between the size of the wings and time spent aloft. In particular...

We can use maths by including latex between dollar signs, for instance $\theta$.


# Results

Our results are summarized in @tbl-modelresults.

```{r}
#| echo: false
#| eval: true
#| warning: false
#| message: false

library(rstanarm)

first_model <-
  readRDS(file = here::here("models/first_model.rds"))
```

```{r}
#| echo: false
#| eval: false
#| label: tbl-modelresults
#| tbl-cap: "Explanatory models of flight time based on wing width and wing length"
#| warning: false

modelsummary::modelsummary(
  list(
    "First model" = first_model
  ),
  statistic = "mad",
  fmt = 2
)
```




# Discussion

## First discussion point {#sec-first-point}

If my paper were 10 pages, then should be be at least 2.5 pages. The discussion is a chance to show off what you know and what you learnt from all this. 

## Second discussion point

Please don't use these as sub-heading labels - change them to be what your point actually is.

## Third discussion point

## Weaknesses and next steps

Weaknesses and next steps should also be included.

\newpage

\appendix

# Appendix {-}


# Additional data details

# Model details {#sec-model-details}

## Posterior predictive check

In @fig-ppcheckandposteriorvsprior-1 we implement a posterior predictive check. This shows...

In @fig-ppcheckandposteriorvsprior-2 we compare the posterior with the prior. This shows... 

```{r}
#| eval: false
#| echo: false
#| message: false
#| warning: false
#| label: fig-ppcheckandposteriorvsprior
#| layout-ncol: 2
#| fig-cap: "Examining how the model fits, and is affected by, the data"
#| fig-subcap: ["Posterior prediction check", "Comparing the posterior with the prior"]

pp_check(first_model) +
  theme_classic() +
  theme(legend.position = "bottom")

posterior_vs_prior(first_model) +
  theme_minimal() +
  scale_color_brewer(palette = "Set1") +
  theme(legend.position = "bottom") +
  coord_flip()
```

## Diagnostics

@fig-stanareyouokay-1 is a trace plot. It shows... This suggests...

@fig-stanareyouokay-2 is a Rhat plot. It shows... This suggests...

```{r}
#| echo: false
#| eval: false
#| message: false
#| warning: false
#| label: fig-stanareyouokay
#| fig-cap: "Checking the convergence of the MCMC algorithm"
#| fig-subcap: ["Trace plot", "Rhat plot"]
#| layout-ncol: 2

plot(first_model, "trace")

plot(first_model, "rhat")
```



\newpage


# References


